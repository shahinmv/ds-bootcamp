{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9facad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51cc285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"heart_disease_dataset.csv\", delimiter = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e37542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1+ np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "  # y_true and y_pred are numpy arrays of the same length.\n",
    "  return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "def mse_loss_derivative(y_true, y_pred):\n",
    "  # y_true and y_pred are numpy arrays of the same length.\n",
    "  return (2*(y_true - y_pred))\n",
    "\n",
    "class ArtificialNeuralNetwork:\n",
    "    def __init__(self, x, y):\n",
    "        self.IN            = x\n",
    "        self.W1            = np.random.rand(self.IN.shape[1],6) \n",
    "        self.W2            = np.random.rand(6,4)\n",
    "        self.W3            = np.random.rand(4,1)\n",
    "        self.y             = y\n",
    "        self.OUT           = np.zeros(self.y.shape)\n",
    "        self.learning_rate = 0.3\n",
    "\n",
    "    def feed_forward(self):\n",
    "        self.HIDDEN_LAYER_1 = sigmoid(np.dot(self.IN, self.W1))\n",
    "        self.HIDDEN_LAYER_2 = sigmoid(np.dot(self.HIDDEN_LAYER_1, self.W2))\n",
    "        self.output = sigmoid(np.dot(self.HIDDEN_LAYER_2, self.W3))\n",
    "\n",
    "    def back_propagate(self):\n",
    "        # application of the chain rule to find derivative of the loss function with respect to W2 and W1\n",
    "        print(self.HIDDEN_LAYER_2.T)\n",
    "        d_W3 = np.dot(self.HIDDEN_LAYER_2.T, (mse_loss_derivative(self.y, self.output) * sigmoid_derivative(self.output)))\n",
    "        print(self.HIDDEN_LAYER_1.T)\n",
    "        d_W2 = np.dot(self.HIDDEN_LAYER_1.T, (mse_loss_derivative(self.y, self.output) * sigmoid_derivative(self.output)))\n",
    "        print(d_W2)\n",
    "        d_W1 = np.dot(self.IN.T,  (mse_loss_derivative(self.y, self.output) * sigmoid_derivative(self.output)))\n",
    "\n",
    "        # update the weights with the derivative (slope) of the loss function\n",
    "        self.W1 += self.learning_rate*d_W1\n",
    "        self.W2 += self.learning_rate*d_W2\n",
    "        self.W3 += self.learning_rate*d_W3\n",
    "\n",
    "    def train(self, epochs,learning_rate):\n",
    "        self.learning_rate=learning_rate\n",
    "        for i in range(epochs):\n",
    "            self.feed_forward()\n",
    "            self.back_propagate()\n",
    "        print(\"Successfully Trained the Model\")\n",
    "        print(\"Weights 1:\", self.W1)\n",
    "        print(\"Weights 2:\", self.W2)\n",
    "        print(\"Weights 3:\", self.W3)\n",
    "    \n",
    "    def print_output(self):\n",
    "        print(self.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ce88a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.replace(' ', '')\n",
    "X = np.array(data.drop(columns=['target']))\n",
    "y = np.reshape(np.array(data.target), (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53a0e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = X.shape\n",
    "my, ny = y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2fbe529a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features - Rows: 303 Columns: 13\n",
      "Target - Rows: 303 Columns: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Features - Rows: {m} Columns: {n}\")\n",
    "print(f\"Target - Rows: {my} Columns: {ny}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a1096f",
   "metadata": {},
   "source": [
    "Input will be each row from the Features column.\n",
    "Output will be each row from target columns, with the dimensions shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d8f9e5",
   "metadata": {},
   "source": [
    "In each iteration(epoch), we find dot product of each layer with the previous layer and apply activation(sigmoid) function. In the back propagation, we find the weight error using mean squared error and adjust our weights by multiplying error by learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eec98141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.88998774 0.88998774 0.88998774 ... 0.88998774 0.88998774 0.88998774]\n",
      " [0.97153014 0.97153014 0.97153014 ... 0.97153014 0.97153014 0.97153014]\n",
      " [0.76568221 0.76568221 0.76568221 ... 0.76568221 0.76568221 0.76568221]\n",
      " [0.92258085 0.92258085 0.92258085 ... 0.92258085 0.92258085 0.92258085]]\n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "[[-17.6543614]\n",
      " [-17.6543614]\n",
      " [-17.6543614]\n",
      " [-17.6543614]\n",
      " [-17.6543614]\n",
      " [-17.6543614]]\n",
      "[[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
      " [0.5 0.5 0.5 ... 0.5 0.5 0.5]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Successfully Trained the Model\n",
      "Weights 1: [[-5.03297314e+02 -5.03600528e+02 -5.04093889e+02 -5.03606487e+02\n",
      "  -5.03679952e+02 -5.03776948e+02]\n",
      " [-7.15931709e+00 -6.98808481e+00 -6.73738468e+00 -6.83623352e+00\n",
      "  -7.00799402e+00 -6.66265038e+00]\n",
      " [-3.14667071e+00 -2.22006418e+00 -3.15841615e+00 -3.01191514e+00\n",
      "  -2.78865803e+00 -3.10390181e+00]\n",
      " [-1.19145875e+03 -1.19203443e+03 -1.19179779e+03 -1.19202138e+03\n",
      "  -1.19137890e+03 -1.19141396e+03]\n",
      " [-2.22595537e+03 -2.22614576e+03 -2.22558695e+03 -2.22599358e+03\n",
      "  -2.22553865e+03 -2.22584605e+03]\n",
      " [-9.04088257e-01 -1.40126685e+00 -7.85525681e-01 -1.07910120e+00\n",
      "  -1.20055267e+00 -9.95874325e-01]\n",
      " [-3.42048619e+00 -3.33316461e+00 -2.82347029e+00 -3.43857558e+00\n",
      "  -3.02854351e+00 -3.25018605e+00]\n",
      " [-1.20517276e+03 -1.20570694e+03 -1.20581637e+03 -1.20515087e+03\n",
      "  -1.20601835e+03 -1.20511114e+03]\n",
      " [-4.76788411e+00 -4.94792781e+00 -4.32923870e+00 -5.26592838e+00\n",
      "  -4.80758466e+00 -5.29319395e+00]\n",
      " [-1.45526282e+01 -1.49433354e+01 -1.44928447e+01 -1.41428802e+01\n",
      "  -1.42489014e+01 -1.46719677e+01]\n",
      " [-9.10885472e+00 -9.03984684e+00 -9.32247251e+00 -9.28878210e+00\n",
      "  -9.66653119e+00 -9.44791567e+00]\n",
      " [-1.10599429e+01 -1.04752704e+01 -1.07251511e+01 -1.07532853e+01\n",
      "  -1.03161662e+01 -1.06745454e+01]\n",
      " [-2.25177059e+01 -2.26579047e+01 -2.28547846e+01 -2.25086606e+01\n",
      "  -2.29010432e+01 -2.26356427e+01]]\n",
      "Weights 2: [[-8.32367119 -7.86124763 -8.71779778 -8.15413964]\n",
      " [-8.32724833 -8.05008247 -8.6835737  -8.74397806]\n",
      " [-8.42796209 -8.03021845 -8.63550496 -8.05940351]\n",
      " [-8.5368827  -8.61028921 -8.81046511 -8.42852164]\n",
      " [-8.44609921 -8.16783576 -8.7562623  -8.67457671]\n",
      " [-8.81060482 -8.71338434 -8.17539142 -8.42452385]]\n",
      "Weights 3: [[-7.53500615]\n",
      " [-8.01790999]\n",
      " [-5.7653046 ]\n",
      " [-7.30925119]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAHIN~1\\AppData\\Local\\Temp/ipykernel_17600/2686365357.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1+ np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "learning_rate = 0.5\n",
    "ann = ArtificialNeuralNetwork(X,y)\n",
    "ann.train(epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c546d1",
   "metadata": {},
   "source": [
    "We stop training when validation error is at minimum. When it reaches minimum, it means that our model has overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78ce3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
